"use strict";(self.webpackChunksap_architecture_center=self.webpackChunksap_architecture_center||[]).push([[9182],{28453:(e,a,t)=>{t.d(a,{R:()=>n,x:()=>o});var i=t(96540);const r={},s=i.createContext(r);function n(e){const a=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:n(e.components),i.createElement(s.Provider,{value:a},e.children)}},62319:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>c,contentTitle:()=>d,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"ref-arch/RA0004/databricks-data-integration/id-ra0004-3","title":"Integration with Databricks","description":"Data from Databricks Lakehouse can be harmonized with SAP and non-sap data via SAP Datasphere\'s unified data models for use with richer analytics and other use cases.","source":"@site/docs/ref-arch/RA0004/3-databricks-data-integration/readme.md","sourceDirName":"ref-arch/RA0004/3-databricks-data-integration","slug":"/ref-arch/28ac36db13/3","permalink":"/ref-arch/28ac36db13/3","draft":false,"unlisted":false,"editUrl":"https://github.com/SAP/architecture-center/edit/main/docs/ref-arch/RA0004/3-databricks-data-integration/readme.md","tags":[{"inline":false,"label":"Data & Analytics","permalink":"/tags/data","description":"Access insights wherever your data resides with SAP data and analytics solutions."}],"version":"current","lastUpdatedBy":"s-krishnamoorthy","lastUpdatedAt":1737590400000,"sidebarPosition":1,"frontMatter":{"id":"id-ra0004-3","slug":"/ref-arch/28ac36db13/3","sidebar_position":1,"sidebar_custom_props":{},"title":"Integration with Databricks","description":"Data from Databricks Lakehouse can be harmonized with SAP and non-sap data via SAP Datasphere\'s unified data models for use with richer analytics and other use cases.","keywords":["sap","databricks","data federation","deltalake","camel JDBC"],"sidebar_label":"Integration with Databricks","image":"img/logo.svg","tags":["data"],"hide_table_of_contents":false,"hide_title":false,"toc_min_heading_level":2,"toc_max_heading_level":4,"draft":false,"unlisted":false,"contributors":["s-krishnamoorthy","chaturvedakash"],"last_update":{"author":"s-krishnamoorthy","date":"2025-01-23T00:00:00.000Z"}},"sidebar":"refarchSidebar","previous":{"title":"Integration with Azure data sources","permalink":"/ref-arch/28ac36db13/2"},"next":{"title":"Integration with Google Cloud Platform sources","permalink":"/ref-arch/28ac36db13/4"}}');var r=t(74848),s=t(28453);const n=t.p+"databricks-data-integration-7b19d7688712d944.drawio",o={id:"id-ra0004-3",slug:"/ref-arch/28ac36db13/3",sidebar_position:1,sidebar_custom_props:{},title:"Integration with Databricks",description:"Data from Databricks Lakehouse can be harmonized with SAP and non-sap data via SAP Datasphere's unified data models for use with richer analytics and other use cases.",keywords:["sap","databricks","data federation","deltalake","camel JDBC"],sidebar_label:"Integration with Databricks",image:"img/logo.svg",tags:["data"],hide_table_of_contents:!1,hide_title:!1,toc_min_heading_level:2,toc_max_heading_level:4,draft:!1,unlisted:!1,contributors:["s-krishnamoorthy","chaturvedakash"],last_update:{author:"s-krishnamoorthy",date:new Date("2025-01-23T00:00:00.000Z")}},d=void 0,c={},l=[{value:"Architecture",id:"architecture",level:2},{value:"1. Integration with Databricks Delta Lake",id:"1-integration-with-databricks-delta-lake",level:2},{value:"Resources",id:"resources",level:2}];function h(e){const a={a:"a",h2:"h2",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components},{DrawioResources:t}=a;return t||function(e,a){throw new Error("Expected "+(a?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("DrawioResources",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(a.p,{children:"Data from Databricks Lakehouse can be harmonized with SAP and non-sap data via SAP Datasphere's unified data models for use with richer analytics and other use cases."}),"\n",(0,r.jsx)(a.h2,{id:"architecture",children:"Architecture"}),"\n",(0,r.jsx)(t,{drawioFile:n}),"\n",(0,r.jsx)(a.h2,{id:"1-integration-with-databricks-delta-lake",children:"1. Integration with Databricks Delta Lake"}),"\n",(0,r.jsxs)(a.p,{children:[(0,r.jsx)(a.strong,{children:"Mode(s) of Integration:"})," Federating data live into SAP Datasphere."]}),"\n",(0,r.jsx)(a.p,{children:"Delta Lake is an optimized storage layer that provides the foundation for tables in a lakehouse architecture on Databricks. It brings reliability to data lakes, ensuring ACID (Atomicity, Consistency, Isolation, Durability) transactions, scalable metadata handling, and unifying streaming and batch data processing."}),"\n",(0,r.jsxs)(a.p,{children:["Data from Databricks Delta Lake tables can be ",(0,r.jsx)(a.strong,{children:"federated"})," live into SAP Datasphere virtual remote models using SAP Datasphere's data federation architecture. This integration allows for the seamless augmentation of Databricks data with SAP business data in real-time. The federated data can be incorporated into unified semantic models, enabling efficient and real-time analytics through SAP Analytics Cloud dashboards."]}),"\n",(0,r.jsx)(a.p,{children:"The integration process involves:"}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Connection Setup"}),": Establishing a secure connection between SAP Datasphere and Databricks Delta Lake using supported connectors and authentication mechanisms."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Data Federation"}),": Configuring virtual tables in SAP Datasphere that reference the live data in Databricks Delta Lake without physically moving the data."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Model Augmentation"}),": Enhancing the federated data with SAP business data to create comprehensive and unified semantic models."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Real-time Analytics"}),": Utilizing SAP Analytics Cloud to build dashboards and reports that leverage the real-time, federated data for actionable insights."]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"This approach ensures that data remains consistent and up-to-date, providing a robust foundation for advanced analytics and decision-making processes."}),"\n",(0,r.jsxs)(a.p,{children:["For detailed step by step information for federating data live from Databricks delta lake, and to try out the integration, visit the Discovery Center mission : ",(0,r.jsx)(a.a,{href:"https://discovery-center.cloud.sap/missiondetail/4259/",children:"Data Federation from Databricks through SAP Datasphere"})]}),"\n",(0,r.jsx)(a.h2,{id:"resources",children:"Resources"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.a,{href:"https://community.sap.com/t5/technology-blogs-by-sap/federating-queries-to-databricks-from-sap-datasphere-for-real-time/ba-p/13564838",children:"Federating queries to Databricks from SAP Datasphere for real-time analytics in SAP Analytics Cloud"})}),"\n"]})]})}function u(e={}){const{wrapper:a}={...(0,s.R)(),...e.components};return a?(0,r.jsx)(a,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}}}]);